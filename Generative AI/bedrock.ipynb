{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\n",
    "    service_name = \"bedrock-runtime\",\n",
    "    region_name = \"us-west-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given lines are for Jurassic (Completion model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello\"\n",
    "\n",
    "kwargs = {\n",
    "    \"modelId\": \"ai21.j2-ultra-v1\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"*/*\",\n",
    "    \"body\": \"{\\\"prompt\\\": \\\"\" + prompt + \"\\\", \\\"maxTokens\\\": 200, \\\"temperature\\\": 0.7, \\\"topP\\\":1}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(**kwargs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(response.get('body').read())\n",
    "completion = response.get('completion', [])[0].get('data', {}).get('text', \"\")\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these for Claude (chat model). It has Anthropic style prompts i.e. human-ai pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello\"\n",
    "\n",
    "kwargs = {\n",
    "    \"modelId\": \"anthroipc.claude-v2\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"*/*\",\n",
    "    \"body\": \"{\\\"prompt\\\": \\\"Human: \" + prompt + \"\\\\nAssistant:\\\", \\\"max_tokens_to_sample\\\": 300, \\\"temperature\\\": 0.7, \\\"topP\\\":1}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(**kwargs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(response.get('body').read())\n",
    "completion = response.get('completion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making chatbot with interactive session\n",
    "\n",
    "- Streaming with claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hi\"\n",
    "kwargs = {\n",
    "    \"modelId\": \"anthropic.claude-v2\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"*/*\",\n",
    "    \"body\": \"{\\\"prompt\\\": \\\"Human: \" + prompt + \"\\\\nAssistant: \\\", \\\"max_tokens_to_sample\\\": 300, \\\"temprature\\\": 0}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_completion(response: dict) -> str:\n",
    "    \"\"\"\n",
    "    function to generate streamed response with bedrock\n",
    "\n",
    "    Params:\n",
    "        response (dict): response obtained from Bedrock\n",
    "    \"\"\"\n",
    "\n",
    "    stream = response.get('body')\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                completion = json.loads(chunk.get('bytes').get('completion'), end=\"\")\n",
    "                print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model_with_response_stream(**kwargs)\n",
    "stream_completion(response=response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
